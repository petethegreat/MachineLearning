---
title: "Activity classification from wearable device measurements"
output:
  html_document:
    mathjax: "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
  pdf_document:
    toc: true
---

===============================
# Introduction

Data comes from XX. Aim is to predict whether subject is performing a weight lifting excercise correctly, or making one of several common mistakes.

Data will first be partitioned and tidied, and then some models will be tuned on the training set

Will use try several models (LDA, random forest, boosted decision tree, SVM, MLP). Will then use these models as component classifiers in an ensemble learning system. Will then assess the final model performance on the test data.

# Data Partitioning

First load required R libraries and set chuk options

load caret and ggplot2

```{r packages, cache=FALSE,message=FALSE,warning=FALSE,echo=FALSE}
library(knitr)
opts_chunk$set(fig.width=6, fig.height=6,dpi=108)
require(ggplot2)
require(dplyr)
require(caret)
require(ranger)
require(MASS)
```
Load data. The `cvtd_time` variable is converted to a posixlt class.

```{r loaddata,cache=TRUE}
training<-read.csv('./data/pml-training.csv',stringsAsFactors=TRUE,na.strings = c("#DIV/0!","NA"))
dim(training)
training$cvtd_timestamp<-strptime(training$cvtd_timestamp,format = "%d/%m/%Y %H:%M")
```

The activity classification is specified in the classe variable. In the training dataset, this is highly correlated with time information:

classe is correlated with time:

```{r timecorr, dependson='loaddata', cache=TRUE}
h<- ggplot(data=training,aes(x=raw_timestamp_part_1,y=classe,colour=classe)) + geom_point()
print(h + scale_x_continuous(limits=c(1323084231,1323084370)))
```
The aim is to predict based on the sensor data. Will omit subject name, time, and window information from the training dataset, As these would not be useful predictors for measurements taken at later dates.

Also, there are a lot of missing values for a number of variables. These could be imputed, but for some of these columns only about 1.5% of the measurements are present. Will omit these variables also.

Finally, will partition the "training" data into training and validation sets. The validation set will be used to assess each model, and also to train the ensemble.

```{r tidy, dependson='loaddata', cache=TRUE}
na_list<-sapply(training,function(x) { sum(is.na(x))})
good<- na_list < 1900
nona<-training[good]
# remove name, time, window info
slimmed<-nona[,-(1:7)]
str(slimmed)
inTrain<-createDataPartition(slimmed$classe,p=0.8,list=FALSE)
slimtr<-slimmed[inTrain,]
slimval<-slimmed[-inTrain,]
```

# Linear Discriminant analysis.

This is like logistic regression for classification. Chapter 4 of ESL is good. All predictor variables are used. K-fold cross validation is used with 10 folds, repeated 3 times. Preditor variables are centred and scaled before the model is trained. This preprocessing is carried out in caret's `train` method, so that the data transformations are computed seperately for each fold, using only the training data in that fold. 

```{r lda,cache=TRUE, dependson='tidy'}
set.seed(5074491)
starttime<-Sys.time()
tr_c<-trainControl(method='repeatedcv',number=10,repeats =3,allowParallel=TRUE) 
ldafit<-train(classe ~ . , data=slimtr, method='lda',trainControl=tr_c, preProcess=c('center','scale'))
endtime<-Sys.time()
endtime - starttime
```

## results
Confusion matrix, error rates, accuracy metrics, etc. cross validation stuff. 


# Random Forest

Use the random forest implementation from the ranger package
Use k-fold cross validation with 3 repeats. mtry parameter is the number of predictor variables sampled at each branch of the tree. 


```{r ranger2, cache=TRUE, dependson='tidy'}
set.seed(5074491)
starttime<-Sys.time()
# tr_c<-trainControl(method='repeatedcv',number=20,repeats=5,allowParallel=TRUE)
tr_c<-trainControl(method='repeatedcv',number=10,repeats=3,allowParallel=TRUE) 

# 20 fold cross validation, repeated 5 times
# can also select 'oob' for out of bag
# model_ranger_nopca<-train(classe~.,data=slim2,method='ranger',trControl=tr_c)
model_ranger2<-train(classe ~ .  ,data=slimtr,method='ranger',trControl=tr_c,tuneGrid = expand.grid(mtry= c(2,10,30)),importance='impurity')
endtime<-Sys.time()
endtime - starttime
```

ranger2 stuff

```{r ranger2stuff,cache=TRUE,dependson='ranger2' }
ggplot(model_ranger2)
model_ranger2
model_ranger2$finalModel
# tr_c<-trainControl(method="cv",preProcOptions = list(thresh = 0.8))
# model_glm<-train(classe~.,data=slimmed,method='glm',family='binomial',train_control=tr_c,preProcess=c('pca','knnImpute'))
# summary(model_glm)
varImp(model_ranger2)
# confusionMatrix
ranger2pred<-predict(model_ranger2,newdata=slimval)
confusionMatrix(data=ranger2pred,reference=slimval$classe)

```

This performs pretty well. Optimal value of mtry was found to be 10. Will try a few more values around here

```{r ranger2a, cache=TRUE, dependson='tidy'}
set.seed(5074491)
starttime<-Sys.time()
# tr_c<-trainControl(method='repeatedcv',number=20,repeats=5,allowParallel=TRUE)
tr_c<-trainControl(method='repeatedcv',number=10,repeats=3,allowParallel=TRUE) 

# 20 fold cross validation, repeated 5 times
# can also select 'oob' for out of bag
# model_ranger_nopca<-train(classe~.,data=slim2,method='ranger',trControl=tr_c)
model_ranger2a<-train(classe ~ .  ,data=slimtr,method='ranger',trControl=tr_c,tuneGrid = expand.grid(mtry= c(6,8,10,12,14)
endtime<-Sys.time()
endtime - starttime
```

any improvement?

```{r ranger2astuff,cache=TRUE,dependson='ranger2' }
ggplot(model_ranger2a)
model_ranger2a
model_ranger2a$finalModel
# tr_c<-trainControl(method="cv",preProcOptions = list(thresh = 0.8))
# model_glm<-train(classe~.,data=slimmed,method='glm',family='binomial',train_control=tr_c,preProcess=c('pca','knnImpute'))
# summary(model_glm)
varImp(model_ranger2a)
# confusionMatrix
ranger2apred<-predict(model_ranger2a,newdata=slimval)
confusionMatrix(data=ranger2preda,reference=slimval$classe)

```

